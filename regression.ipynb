{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6f012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24beb50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_intercept(X):\n",
    "    \"\"\"\n",
    "    Return X with a leading column of ones (bias term).\n",
    "    X: (n_samples, n_features) -> (n_samples, n_features + 1)\n",
    "    Notes: ensure float dtype; do not modify X in-place.\n",
    "    \"\"\"\n",
    "    new_X = np.asarray(X, dtype=float)\n",
    "    ones = np.ones((new_X.shape[0], 1))\n",
    "    return np.hstack((ones, new_X))\n",
    "\n",
    "\n",
    "def standardize_fit(X_train, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Standardize TRAIN features to zero mean / unit variance.\n",
    "    1\n",
    "    Return (Xs, mean, std). Use only TRAIN stats.\n",
    "    \"\"\"\n",
    "    mean = np.mean(X_train, axis=0)\n",
    "    std = np.std(X_train, axis=0)\n",
    "    Xs = (X_train - mean) / (std + eps)\n",
    "    return Xs, mean, std\n",
    "\n",
    "def standardize_apply(X, mean, std, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Apply TRAIN (mean, std) to any new matrix X.\n",
    "    Do not recompute mean/std here.\n",
    "    \"\"\"\n",
    "    return (X - mean) / (std + eps)\n",
    "\n",
    "\n",
    "def train_test_split_idx(n, test_size, seed=0):\n",
    "    \"\"\"\n",
    "    Return (train_idx, test_idx) with fixed RNG.\n",
    "    You may also use sklearn’s splitter to obtain indices only.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    indices = np.arange(n)\n",
    "    rng.shuffle(indices)\n",
    "\n",
    "    test_count = int(np.floor(n * test_size))\n",
    "    test_idx = indices[:test_count]\n",
    "    train_idx = indices[test_count:]\n",
    "    return train_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba7e613",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('train.csv')\n",
    "\n",
    "print(\"Shape of Dataset:\", training_data.shape)\n",
    "print(\"\\nColumn Types:\")\n",
    "print(training_data.dtypes)\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(training_data.isna().sum())\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(training_data.describe())\n",
    "\n",
    "# %%\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b953313",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(training_data[\"trip_duration\"], bins=50, edgecolor='black')\n",
    "plt.title(\"Trip Duration Distribution\")\n",
    "plt.xlabel(\"Duration (seconds)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(np.log1p(training_data[\"trip_duration\"]), bins=50, edgecolor='black')\n",
    "plt.title(\"Trip Duration Distribution (Log-Transformed)\")\n",
    "plt.xlabel(\"log(1 + duration)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d90bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,6))\n",
    "plt.scatter(training_data[\"pickup_longitude\"], training_data[\"pickup_latitude\"], s=1, alpha=0.3, color='green')\n",
    "plt.scatter(training_data[\"dropoff_longitude\"], training_data[\"dropoff_latitude\"], s=1, alpha=0.3, color='red')\n",
    "plt.title(\"Pickup and Dropoff Locations (Lon vs Lat)\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bd731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return 6371 * c  # km\n",
    "\n",
    "training_data[\"distance_km\"] = haversine(\n",
    "    training_data[\"pickup_longitude\"], training_data[\"pickup_latitude\"],\n",
    "    training_data[\"dropoff_longitude\"], training_data[\"dropoff_latitude\"]\n",
    ")\n",
    "\n",
    "print(\"\\nDistance feature added.\")\n",
    "print(training_data[\"distance_km\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292112dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(training_data[\"distance_km\"], training_data[\"trip_duration\"], s=3, alpha=0.3)\n",
    "plt.title(\"Distance vs Trip Duration\")\n",
    "plt.xlabel(\"Distance (km)\")\n",
    "plt.ylabel(\"Duration (sec)\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(np.log1p(training_data[\"distance_km\"]), np.log1p(training_data[\"trip_duration\"]), s=3, alpha=0.3)\n",
    "plt.title(\"log(Distance) vs log(Duration)\")\n",
    "plt.xlabel(\"log(1 + distance)\")\n",
    "plt.ylabel(\"log(1 + duration)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b44adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "training_data[\"pickup_datetime\"] = pd.to_datetime(training_data[\"pickup_datetime\"])\n",
    "training_data[\"hour\"] = training_data[\"pickup_datetime\"].dt.hour\n",
    "training_data[\"day_of_week\"] = training_data[\"pickup_datetime\"].dt.dayofweek\n",
    "training_data[\"month\"] = training_data[\"pickup_datetime\"].dt.month\n",
    "\n",
    "print(\"\\nTemporal features added:\")\n",
    "print(training_data[[\"hour\", \"day_of_week\", \"month\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f465b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.lineplot(data=training_data, x=\"hour\", y=\"trip_duration\", errorbar=None)\n",
    "plt.title(\"Average Trip Duration vs Hour of Day\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.boxplot(data=training_data, x=\"day_of_week\", y=\"trip_duration\")\n",
    "plt.title(\"Trip Duration vs Day of Week\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.boxplot(data=training_data, x=\"month\", y=\"trip_duration\")\n",
    "plt.title(\"Trip Duration vs Month\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9f31d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(x=\"vendor_id\", y=\"trip_duration\", data=training_data)\n",
    "plt.title(\"Trip Duration by Vendor\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(x=\"store_and_fwd_flag\", y=\"trip_duration\", data=training_data)\n",
    "plt.title(\"Trip Duration by store_and_fwd_flag\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9200ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(x=training_data[\"trip_duration\"])\n",
    "plt.title(\"Trip Duration Outlier Detection\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.scatterplot(x=training_data[\"distance_km\"], y=training_data[\"trip_duration\"], alpha=0.3)\n",
    "plt.title(\"Outliers in Distance vs Duration\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512f7f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "corr_features = training_data[[\n",
    "    \"trip_duration\", \"distance_km\", \"hour\",\n",
    "    \"day_of_week\", \"month\", \"passenger_count\"\n",
    "]]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(corr_features.corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81026da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi = training_data.copy()\n",
    "\n",
    "taxi = taxi[(taxi[\"trip_duration\"] <= 7200) & (taxi[\"distance_km\"] > 0)]\n",
    "valid_lat = taxi[\"pickup_latitude\"].between(40.3, 41.2) & taxi[\"dropoff_latitude\"].between(40.3, 41.2)\n",
    "valid_lon = taxi[\"pickup_longitude\"].between(-74.5, -72.8) & taxi[\"dropoff_longitude\"].between(-74.5, -72.8)\n",
    "\n",
    "taxi = taxi[valid_lat & valid_lon]\n",
    "\n",
    "taxi[\"distance_km\"] = haversine(\n",
    "    taxi[\"pickup_latitude\"], taxi[\"pickup_longitude\"],\n",
    "    taxi[\"dropoff_latitude\"], taxi[\"dropoff_longitude\"]\n",
    ")\n",
    "\n",
    "taxi = taxi[(taxi[\"distance_km\"] > 0) &(taxi[\"distance_km\"]<=100)]\n",
    "\n",
    "\n",
    "same_point = (\n",
    "    (taxi[\"pickup_longitude\"] == taxi[\"dropoff_longitude\"]) &\n",
    "    (taxi[\"pickup_latitude\"] == taxi[\"dropoff_latitude\"])\n",
    ")\n",
    "\n",
    "taxi = taxi[~same_point]\n",
    "\n",
    "taxi = taxi.reset_index(drop=True)\n",
    "\n",
    "print(\"\\nFinal cleaned dataset shape:\", taxi.shape)\n",
    "taxi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b909ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = taxi.copy()\n",
    "\n",
    "df[\"pickup_datetime\"] = pd.to_datetime(df[\"pickup_datetime\"])\n",
    "\n",
    "df[\"hour\"] = df[\"pickup_datetime\"].dt.hour\n",
    "df[\"day_of_week\"] = df[\"pickup_datetime\"].dt.dayofweek\n",
    "df[\"month\"] = df[\"pickup_datetime\"].dt.month\n",
    "\n",
    "df[\"ch_lat\"] = (df[\"dropoff_latitude\"] - df[\"pickup_latitude\"]).abs()\n",
    "df[\"ch_lon\"] = (df[\"dropoff_longitude\"] - df[\"pickup_longitude\"]).abs()\n",
    "\n",
    "df[\"sq_dist\"] = df[\"distance_km\"] ** 2  \n",
    "df[\"log_distance\"] = np.log1p(df[\"distance_km\"])\n",
    "df[\"store_and_fwd_flag\"] = df[\"store_and_fwd_flag\"].map({'N': 0, 'Y': 1})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39c2ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(df[\"trip_duration\"], bins=50, edgecolor='black')\n",
    "plt.title(\"Trip Duration Distribution (Raw)\")\n",
    "plt.xlabel(\"Duration (seconds)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba165125",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"log_trip_duration\"] = np.log1p(df[\"trip_duration\"])\n",
    "\n",
    "feature_cols = [\n",
    "    \"distance_km\",\n",
    "    \"log_distance\",\n",
    "    \"sq_dist\",\n",
    "    \"hour\",\n",
    "    \"day_of_week\",\n",
    "    \"month\",\n",
    "    \"ch_lat\",\n",
    "    \"ch_lon\",\n",
    "    \"vendor_id\",\n",
    "    \"store_and_fwd_flag\",\n",
    "    \"passenger_count\"\n",
    "]\n",
    "\n",
    "target_col = \"log_trip_duration\"\n",
    "print(df.columns)\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df[target_col].values\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Target vector shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c155373e",
   "metadata": {},
   "source": [
    "### Preparing the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e2ae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw = pd.read_csv('test.csv')\n",
    "test_df = test_raw.copy()\n",
    "\n",
    "test_df = test_df.copy()\n",
    "test_df = test_df.dropna()\n",
    "valid_lat = test_df[\"pickup_latitude\"].between(40.3, 41.2) & test_df[\"dropoff_latitude\"].between(40.3, 41.2)\n",
    "valid_lon = test_df[\"pickup_longitude\"].between(-74.5, -72.8) & test_df[\"dropoff_longitude\"].between(-74.5, -72.8)\n",
    "\n",
    "test_df = test_df[valid_lat & valid_lon]\n",
    "\n",
    "test_df[\"distance_km\"] = haversine(\n",
    "    test_df[\"pickup_longitude\"], test_df[\"pickup_latitude\"],\n",
    "    test_df[\"dropoff_longitude\"], test_df[\"dropoff_latitude\"]\n",
    ")\n",
    "\n",
    "test_df = test_df[(test_df[\"distance_km\"] > 0) &(test_df[\"distance_km\"]<=100)]\n",
    "same_point = (\n",
    "    (test_df[\"pickup_longitude\"] == test_df[\"dropoff_longitude\"]) &\n",
    "    (test_df[\"pickup_latitude\"] == test_df[\"dropoff_latitude\"])\n",
    ")\n",
    "\n",
    "test_df = test_df[~same_point]\n",
    "\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "test_df[\"pickup_datetime\"] = pd.to_datetime(test_df[\"pickup_datetime\"])\n",
    "test_df[\"hour\"] = test_df[\"pickup_datetime\"].dt.hour\n",
    "test_df[\"day_of_week\"] = test_df[\"pickup_datetime\"].dt.dayofweek\n",
    "test_df[\"month\"] = test_df[\"pickup_datetime\"].dt.month\n",
    "\n",
    "test_df[\"ch_lat\"] = (test_df[\"dropoff_latitude\"] - test_df[\"pickup_latitude\"]).abs()\n",
    "test_df[\"ch_lon\"] = (test_df[\"dropoff_longitude\"] - test_df[\"pickup_longitude\"]).abs()  \n",
    "\n",
    "test_df[\"sq_dist\"] = test_df[\"distance_km\"] ** 2\n",
    "test_df[\"log_distance\"] = np.log1p(test_df[\"distance_km\"])\n",
    "test_df[\"store_and_fwd_flag\"] = test_df[\"store_and_fwd_flag\"].map({'N': 0, 'Y': 1}) \n",
    "\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "print(test_df.columns)\n",
    "test_X = test_df[feature_cols].values\n",
    "\n",
    "train_idx, val_idx = train_test_split_idx(len(X), test_size=0.2, seed=42)\n",
    "X_train, X_val = X[train_idx], X[val_idx]\n",
    "y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape)\n",
    "print(\"Test set shape:\", test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679b473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std, mean, std = standardize_fit(X_train)\n",
    "X_val_std = standardize_apply(X_val, mean, std)\n",
    "test_X_std = standardize_apply(test_X, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1da910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y, yhat):\n",
    "    \"\"\"Mean squared error: average of (y - yhat)^2 (1D arrays).\"\"\"\n",
    "    diff = y - yhat\n",
    "    diff_sq = diff ** 2\n",
    "    return np.mean(diff_sq)\n",
    "\n",
    "def r2_score(y, yhat):\n",
    "    \"\"\"1 - SS_res/SS_tot; handle constant-y edge case safely.\"\"\"\n",
    "    ss_res = np.sum((y - yhat) ** 2)\n",
    "    ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "    if ss_tot == 0:\n",
    "        return 0.0\n",
    "    return 1 - (ss_res / ss_tot)\n",
    "\n",
    "def fit_linear_closed_form(X, y, add_bias=True, rcond=None):\n",
    "    \"\"\"\n",
    "    Closed-form least squares (MLE) using pseudoinverse or solve.\n",
    "    Steps:\n",
    "    * If add_bias: prepend ones.\n",
    "    * Prefer pinv for numerical stability when X^T X is ill-conditioned.\n",
    "    Return w (length p [+1 if bias]).\n",
    "    \"\"\"\n",
    "    X_mat = np.asarray(X, dtype=float)\n",
    "    if add_bias:\n",
    "        X_mat = add_intercept(X_mat)\n",
    "    y_vec = np.asarray(y, dtype=float)\n",
    "\n",
    "    condition_number = np.linalg.cond(X_mat.T @ X_mat)\n",
    "    print(f\"Condition number: {condition_number:.2e}\")\n",
    "    if condition_number < 1e8:\n",
    "        w = np.linalg.solve(X_mat.T @ X_mat, X_mat.T @ y_vec)\n",
    "        return w\n",
    "    else:\n",
    "        w = np.linalg.pinv(X_mat, rcond=rcond) @ y_vec\n",
    "        return w\n",
    "\n",
    "def fit_linear_gd(X, y, lr=0.05, iters=5000, add_bias=True):\n",
    "    \"\"\"\n",
    "    Batch gradient descent for least squares.\n",
    "    Return (w, losses).\n",
    "    \"\"\"\n",
    "    X_mat = np.asarray(X, dtype=float)\n",
    "    if add_bias:\n",
    "        X_mat = add_intercept(X_mat)\n",
    "    y_vec = np.asarray(y, dtype=float)\n",
    "    n_samples, n_features = X_mat.shape\n",
    "    w = np.zeros(n_features)\n",
    "    losses = []\n",
    "\n",
    "    for i in range(iters):\n",
    "        yhat = X_mat @ w\n",
    "        loss = mse(y_vec, yhat)\n",
    "        losses.append(loss)\n",
    "\n",
    "        gradient = -2 * (X_mat.T @ (y_vec - yhat)) / n_samples\n",
    "        w -= lr * gradient\n",
    "\n",
    "    return w, np.array(losses)\n",
    "\n",
    "def predict_linear(X, w, has_bias=True):\n",
    "    \"\"\"Predict with linear model; add bias column if has_bias. Return 1D yhat.\"\"\"\n",
    "    X_mat = np.asarray(X, dtype=float)\n",
    "    if has_bias:\n",
    "        X_mat = add_intercept(X_mat)\n",
    "    w_vec = np.asarray(w, dtype=float)\n",
    "    return X_mat @ w_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceebf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_closed = fit_linear_closed_form(X_train_std, y_train, add_bias=True)\n",
    "\n",
    "y_train_pred = predict_linear(X_train_std, w_closed, has_bias=True)\n",
    "y_val_pred = predict_linear(X_val_std, w_closed, has_bias=True)\n",
    "\n",
    "print(\"\\nClosed-Form Linear Regression Results:\")\n",
    "print(\"Training MSE:\", mse(y_train, y_train_pred))\n",
    "print(\"Validation MSE:\", mse(y_val, y_val_pred))\n",
    "\n",
    "print(\"Training R²:\", r2_score(y_train, y_train_pred))\n",
    "print(\"Validation R²:\", r2_score(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47080177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Predict on test data\n",
    "test_pred_log = predict_linear(test_X_std, w_closed, has_bias=True)\n",
    "\n",
    "# Convert back from log scale\n",
    "test_pred_duration = np.expm1(test_pred_log)\n",
    "\n",
    "test_pred_duration[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc381c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def polynomial_features_degree2(X):\n",
    "    \"\"\"\n",
    "    Generate polynomial features (degree 2) from matrix X.\n",
    "    Includes:\n",
    "      - all original features\n",
    "      - all squared terms\n",
    "      - all pairwise interaction terms\n",
    "    Input:\n",
    "        X : numpy array (n_samples, n_features)\n",
    "    Output:\n",
    "        X_poly : array (n_samples, n_output_features)\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    n_samples, n_features = X.shape\n",
    "    poly_list = []\n",
    "\n",
    "    # 1. original features\n",
    "    poly_list.append(X)\n",
    "\n",
    "    # 2. squared terms\n",
    "    poly_list.append(X ** 2)\n",
    "\n",
    "    # 3. interaction terms x_i * x_j (i < j)\n",
    "    interaction_terms = []\n",
    "    for i in range(n_features):\n",
    "        for j in range(i + 1, n_features):\n",
    "            interaction_terms.append((X[:, i] * X[:, j]).reshape(-1, 1))\n",
    "\n",
    "    if interaction_terms:\n",
    "        poly_list.append(np.hstack(interaction_terms))\n",
    "\n",
    "    # Final polynomial matrix\n",
    "    X_poly = np.hstack(poly_list)\n",
    "    return X_poly\n",
    "\n",
    "def polynomial_features(X, degree):\n",
    "    \"\"\"\n",
    "    Generate polynomial features up to a given degree.\n",
    "    Includes ONLY monomials (x_i, x_i^2, ..., x_i^degree)\n",
    "    for stability and speed.\n",
    "    \n",
    "    X: (n_samples, n_features)\n",
    "    degree: integer >= 1\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    poly_list = [X]  # degree 1\n",
    "    \n",
    "    # degrees 2..d (monomials only)\n",
    "    for deg in range(2, degree + 1):\n",
    "        poly_list.append(X ** deg)\n",
    "        \n",
    "    return np.hstack(poly_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caacbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_poly_degree(X_train, y_train, X_val, y_val, degree):\n",
    "    # 1. Build polynomial features\n",
    "    X_train_poly = polynomial_features_degree2(X_train) if degree == 2 else polynomial_features(X_train, degree)\n",
    "    X_val_poly   = polynomial_features_degree2(X_val) if degree == 2 else polynomial_features(X_val, degree)\n",
    "    \n",
    "    # 2. Standardize\n",
    "    X_train_poly_std, mean_p, std_p = standardize_fit(X_train_poly)\n",
    "    X_val_poly_std   = standardize_apply(X_val_poly, mean_p, std_p)\n",
    "    \n",
    "    # 3. Fit closed-form linear regression\n",
    "    w = fit_linear_closed_form(X_train_poly_std, y_train, add_bias=True)\n",
    "    \n",
    "    # 4. Predictions\n",
    "    y_train_pred = predict_linear(X_train_poly_std, w)\n",
    "    y_val_pred   = predict_linear(X_val_poly_std, w)\n",
    "    \n",
    "    # 5. Metrics\n",
    "    train_mse = mse(y_train, y_train_pred)\n",
    "    val_mse   = mse(y_val, y_val_pred)\n",
    "    train_r2  = r2_score(y_train, y_train_pred)\n",
    "    val_r2    = r2_score(y_val, y_val_pred)\n",
    "    \n",
    "    return {\n",
    "        \"degree\": degree,\n",
    "        \"w\": w,\n",
    "        \"train_mse\": train_mse,\n",
    "        \"val_mse\": val_mse,\n",
    "        \"train_r2\": train_r2,\n",
    "        \"val_r2\": val_r2\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f51ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEvaluating polynomial degrees 1 to 3...\")\n",
    "results = []\n",
    "\n",
    "for deg in [1, 2, 3]:\n",
    "    res = evaluate_poly_degree(X_train_std, y_train, X_val_std, y_val, degree=deg)\n",
    "    results.append(res)\n",
    "    print(f\"Degree {deg}: Train MSE={res['train_mse']:.4f}, Val MSE={res['val_mse']:.4f}, Train R²={res['train_r2']:.4f}, Val R²={res['val_r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3d9812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ridge_closed_form(X, y, lam, add_bias=True):\n",
    "    \"\"\"\n",
    "    Closed-form ridge regression.\n",
    "    Does NOT regularize intercept.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, float)\n",
    "    y = np.asarray(y, float)\n",
    "    \n",
    "    if add_bias:\n",
    "        X = add_intercept(X)\n",
    "    \n",
    "    n_features = X.shape[1]\n",
    "    \n",
    "    # Regularization matrix\n",
    "    I = np.eye(n_features)\n",
    "    I[0, 0] = 0.0   # do not regularize bias\n",
    "    \n",
    "    # Closed form ridge solution\n",
    "    A = X.T @ X + lam * I\n",
    "    b = X.T @ y\n",
    "    \n",
    "    w = np.linalg.solve(A, b)\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202c21a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ridge_gd(X, y, lam, lr=0.01, iters=3000, add_bias=True):\n",
    "    X = np.asarray(X, float)\n",
    "    y = np.asarray(y, float)\n",
    "    \n",
    "    if add_bias:\n",
    "        X = add_intercept(X)\n",
    "        \n",
    "    n_samples, n_features = X.shape\n",
    "    w = np.zeros(n_features)\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for _ in range(iters):\n",
    "        yhat = X @ w\n",
    "        error = yhat - y\n",
    "        \n",
    "        grad = (X.T @ error) / n_samples\n",
    "        grad[1:] += lam * w[1:] / n_samples   # no penalty on bias\n",
    "        \n",
    "        w -= lr * grad\n",
    "        \n",
    "        losses.append(mse(y, X @ w))\n",
    "    \n",
    "    return w, losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8d1288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_threshold(z, lam):\n",
    "    if z > lam:\n",
    "        return z - lam\n",
    "    elif z < -lam:\n",
    "        return z + lam\n",
    "    else:\n",
    "        return 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a77838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lasso_cd(X, y, lam, iters=100):\n",
    "    \"\"\"\n",
    "    Lasso Regression using coordinate descent.\n",
    "    Does NOT regularize intercept.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, float)\n",
    "    y = np.asarray(y, float)\n",
    "    \n",
    "    X = add_intercept(X)\n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    w = np.zeros(n_features)\n",
    "    \n",
    "    for _ in range(iters):\n",
    "        # update intercept separately (no regularization)\n",
    "        y_pred = X @ w\n",
    "        r = y - y_pred\n",
    "        w[0] += np.mean(r)\n",
    "        \n",
    "        # update each feature weight\n",
    "        for j in range(1, n_features):\n",
    "            # compute partial residual\n",
    "            y_pred = X @ w\n",
    "            r_j = y - (y_pred - X[:, j] * w[j])\n",
    "            \n",
    "            # update using soft thresholding\n",
    "            rho = np.dot(X[:, j], r_j)\n",
    "            z = np.dot(X[:, j], X[:, j])\n",
    "            \n",
    "            w[j] = soft_threshold(rho / z, lam / z)\n",
    "    \n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a33007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_train, y_train, X_val, y_val, degree, model_type, lam=0.0):\n",
    "    \n",
    "    # 1. Polynomial features\n",
    "    X_train_poly = polynomial_features_degree2(X_train) if degree == 2 else polynomial_features(X_train, degree)\n",
    "    X_val_poly   = polynomial_features_degree2(X_val) if degree == 2 else polynomial_features(X_val, degree)\n",
    "    \n",
    "    # 2. Standardize\n",
    "    X_train_std, mean_, std_ = standardize_fit(X_train_poly)\n",
    "    X_val_std = standardize_apply(X_val_poly, mean_, std_)\n",
    "    \n",
    "    # 3. Fit model\n",
    "    if model_type == \"ridge\":\n",
    "        w = fit_ridge_closed_form(X_train_std, y_train, lam, add_bias=True)\n",
    "        \n",
    "    elif model_type == \"lasso\":\n",
    "        w = fit_lasso_cd(X_train_std, y_train, lam, iters=50)\n",
    "        \n",
    "    elif model_type == \"linear\":\n",
    "        w = fit_linear_closed_form(X_train_std, y_train, add_bias=True)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type.\")\n",
    "    \n",
    "    # 4. Predictions\n",
    "    y_train_pred = predict_linear(X_train_std, w)\n",
    "    y_val_pred   = predict_linear(X_val_std, w)\n",
    "    \n",
    "    return {\n",
    "        \"degree\": degree,\n",
    "        \"lambda\": lam,\n",
    "        \"model\": model_type,\n",
    "        \"w\": w,\n",
    "        \"train_mse\": mse(y_train, y_train_pred),\n",
    "        \"val_mse\": mse(y_val,  y_val_pred),\n",
    "        \"train_r2\": r2_score(y_train, y_train_pred),\n",
    "        \"val_r2\": r2_score(y_val,  y_val_pred)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41e9dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_split(X, y, k=5, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(X)\n",
    "    indices = np.arange(n)\n",
    "    rng.shuffle(indices)\n",
    "\n",
    "    fold_sizes = (n // k) * np.ones(k, dtype=int)\n",
    "    fold_sizes[: n % k] += 1\n",
    "\n",
    "    folds = []\n",
    "    start = 0\n",
    "    for size in fold_sizes:\n",
    "        end = start + size\n",
    "        folds.append(indices[start:end])\n",
    "        start = end\n",
    "\n",
    "    return folds\n",
    "\n",
    "def cross_val_evaluate(X, y, degree, model_type, lam=0.0, k=5):\n",
    "    folds = kfold_split(X, y, k=k)\n",
    "\n",
    "    mse_scores = []\n",
    "    r2_scores = []\n",
    "\n",
    "    for i in range(k):\n",
    "        val_idx = folds[i]\n",
    "        train_idx = np.hstack([folds[j] for j in range(k) if j != i])\n",
    "\n",
    "        X_train_cv, y_train_cv = X[train_idx], y[train_idx]\n",
    "        X_val_cv, y_val_cv = X[val_idx], y[val_idx]\n",
    "\n",
    "        # Polynomial expansion\n",
    "        X_train_poly = polynomial_features(X_train_cv, degree)\n",
    "        X_val_poly = polynomial_features(X_val_cv, degree)\n",
    "\n",
    "        # Standardization\n",
    "        X_train_std, mean_, std_ = standardize_fit(X_train_poly)\n",
    "        X_val_std = standardize_apply(X_val_poly, mean_, std_)\n",
    "\n",
    "        # Fit model\n",
    "        if model_type == \"linear\":\n",
    "            w = fit_linear_closed_form(X_train_std, y_train_cv, add_bias=True)\n",
    "\n",
    "        elif model_type == \"ridge\":\n",
    "            w = fit_ridge_closed_form(X_train_std, y_train_cv, lam, add_bias=True)\n",
    "\n",
    "        elif model_type == \"lasso\":\n",
    "            w = fit_lasso_cd(X_train_std, y_train_cv, lam, iters=50)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = predict_linear(X_val_std, w)\n",
    "\n",
    "        # Store metrics\n",
    "        mse_scores.append(mse(y_val_cv, y_pred))\n",
    "        r2_scores.append(r2_score(y_val_cv, y_pred))\n",
    "\n",
    "    return {\n",
    "        \"degree\": degree,\n",
    "        \"lambda\": lam,\n",
    "        \"model\": model_type,\n",
    "        \"cv_mse\": np.mean(mse_scores),\n",
    "        \"cv_r2\": np.mean(r2_scores)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cc4c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = [1, 2, 3]\n",
    "lambdas = [0.01, 0.1, 1, 10]\n",
    "\n",
    "results = []\n",
    "\n",
    "for d in degrees:\n",
    "    for lam in lambdas:\n",
    "        print(f\"CV Ridge: degree={d}, lambda={lam}\")\n",
    "        res = cross_val_evaluate(X_train, y_train, degree=d, model_type=\"ridge\", lam=lam, k=5)\n",
    "        results.append(res)\n",
    "\n",
    "for d in degrees:\n",
    "    for lam in lambdas:\n",
    "        print(f\"CV Lasso: degree={d}, lambda={lam}\")\n",
    "        res = cross_val_evaluate(X_train, y_train, degree=d, model_type=\"lasso\", lam=lam, k=5)\n",
    "        results.append(res)\n",
    "\n",
    "for d in degrees:\n",
    "    print(f\"CV Linear: degree={d}\")\n",
    "    res = cross_val_evaluate(X_train, y_train, degree=d, model_type=\"linear\", lam=0.0, k=5)\n",
    "    results.append(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e91ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = min(results, key=lambda r: r[\"cv_mse\"])\n",
    "\n",
    "print(\"\\n======= BEST MODEL (5-fold CV) =======\")\n",
    "print(f\"Model  : {best_model['model']}\")\n",
    "print(f\"Degree : {best_model['degree']}\")\n",
    "print(f\"Lambda : {best_model['lambda']}\")\n",
    "print(f\"CV MSE : {best_model['cv_mse']:.4f}\")\n",
    "print(f\"CV R²  : {best_model['cv_r2']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eab8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_degree = 3\n",
    "best_lam = 10\n",
    "best_type = \"ridge\"\n",
    "\n",
    "# Build polynomial features\n",
    "X_train_best_poly = polynomial_features(X_train, best_degree)\n",
    "X_test_best_poly  = polynomial_features(test_X, best_degree)\n",
    "\n",
    "# Standardize\n",
    "X_train_best_std, mean_b, std_b = standardize_fit(X_train_best_poly)\n",
    "X_test_best_std = standardize_apply(X_test_best_poly, mean_b, std_b)\n",
    "\n",
    "# Fit final model\n",
    "if best_type == \"linear\":\n",
    "    w_best = fit_linear_closed_form(X_train_best_std, y_train, add_bias=True)\n",
    "\n",
    "elif best_type == \"ridge\":\n",
    "    w_best = fit_ridge_closed_form(X_train_best_std, y_train, best_lam, add_bias=True)\n",
    "\n",
    "elif best_type == \"lasso\":\n",
    "    w_best = fit_lasso_cd(X_train_best_std, y_train, best_lam, iters=100)\n",
    "\n",
    "print(\"Final model trained.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe46f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_log = predict_linear(X_test_best_std, w_best)\n",
    "test_pred = np.expm1(test_pred_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95985ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_poly = polynomial_features(X_train, best_degree)\n",
    "X_val_poly   = polynomial_features(X_val, best_degree)\n",
    "\n",
    "X_train_std, mean_best, std_best = standardize_fit(X_train_poly)\n",
    "X_val_std = standardize_apply(X_val_poly, mean_best, std_best)\n",
    "\n",
    "y_train_reg = y_train\n",
    "y_val_reg   = y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb3dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2fdec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    n_estimators=150,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train_std, y_train_reg)\n",
    "\n",
    "rf_train_pred = rf.predict(X_train_std)\n",
    "rf_val_pred   = rf.predict(X_val_std)\n",
    "\n",
    "rf_results = {\n",
    "    \"model\": \"Random Forest\",\n",
    "    \"train_mse\": mse(y_train_reg, rf_train_pred),\n",
    "    \"val_mse\": mse(y_val_reg, rf_val_pred),\n",
    "    \"train_r2\": r2_score(y_train_reg, rf_train_pred),\n",
    "    \"val_r2\": r2_score(y_val_reg, rf_val_pred)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaddb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.08,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\"\n",
    ")\n",
    "xgb.fit(X_train_std, y_train_reg)\n",
    "\n",
    "xgb_train_pred = xgb.predict(X_train_std)\n",
    "xgb_val_pred   = xgb.predict(X_val_std)\n",
    "\n",
    "xgb_results = {\n",
    "    \"model\": \"XGBoost\",\n",
    "    \"train_mse\": mse(y_train_reg, xgb_train_pred),\n",
    "    \"val_mse\": mse(y_val_reg, xgb_val_pred),\n",
    "    \"train_r2\": r2_score(y_train_reg, xgb_train_pred),\n",
    "    \"val_r2\": r2_score(y_val_reg, xgb_val_pred)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa9702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_best = predict_linear(X_train_std, w_best)\n",
    "y_val_pred_best   = predict_linear(X_val_std, w_best)\n",
    "\n",
    "best_custom_results = {\n",
    "    \"model\": f\"Custom {best_type} (degree={best_degree}, λ={best_lam})\",\n",
    "    \"train_mse\": mse(y_train_reg, y_train_pred_best),\n",
    "    \"val_mse\": mse(y_val_reg,  y_val_pred_best),\n",
    "    \"train_r2\": r2_score(y_train_reg, y_train_pred_best),\n",
    "    \"val_r2\": r2_score(y_val_reg,  y_val_pred_best)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f42ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comparison_df = pd.DataFrame([\n",
    "    best_custom_results,\n",
    "    rf_results,\n",
    "    xgb_results\n",
    "])\n",
    "\n",
    "print(\"\\n======= Model Comparison =======\")\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e001c28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
